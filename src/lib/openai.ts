import OpenAI from 'openai';

export const openai = new OpenAI({ 
  apiKey: import.meta.env.VITE_OPENAI_KEY || process.env.OPENAI_API_KEY || 'your-api-key-here',
  dangerouslyAllowBrowser: true,
  timeout: 30 * 1000, // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–æ 30 —Å–µ–∫—É–Ω–¥
  maxRetries: 0,      // –û—Ç–∫–ª—é—á–∞–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ retry, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–≤–æ–∏
});

// Retry helper —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –æ—à–∏–±–æ–∫
async function retryWithBackoff<T>(
  fn: () => Promise<T>, 
  maxRetries: number = 2, 
  backoffMs: number = 500
): Promise<T> {
  let lastError: any;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error: any) {
      lastError = error;
      
      // –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ (—Ç–æ–∫–µ–Ω—ã, –ª–∏–º–∏—Ç—ã, etc.)
      if (error?.status) {
        console.log(`üîç OpenAI API Error - Status: ${error.status}, Attempt: ${attempt + 1}/${maxRetries + 1}`);
        
        if (error.status === 429) {
          console.log('‚ö†Ô∏è Rate limit exceeded (429) - –≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å —Ç–æ–∫–µ–Ω—ã –∏–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤');
        } else if (error.status >= 500) {
          console.log('üí• Server error (5xx) - –ø—Ä–æ–±–ª–µ–º—ã –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ OpenAI');
        }
      }
      
      // –ï—Å–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞, –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É
      if (attempt === maxRetries) {
        throw lastError;
      }
      
      // Backoff –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
      console.log(`‚è≥ Waiting ${backoffMs}ms before retry...`);
      await new Promise(resolve => setTimeout(resolve, backoffMs));
      backoffMs *= 2; // –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π backoff
    }
  }
  
  throw lastError;
}

export async function callGPT(prompt: string) {
  return retryWithBackoff(async () => {
    const r = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }]
    });
    return r.choices[0].message.content;
  });
}

export async function callGPTWithSystem(
  system: string,
  user: string,
  opts = {}
) {
  return retryWithBackoff(async () => {
    const r = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: system },
        { role: 'user', content: user }
      ],
      ...opts
    });
    return r.choices[0].message.content;
  });
}
